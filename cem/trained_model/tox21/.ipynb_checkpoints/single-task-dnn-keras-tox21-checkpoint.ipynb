{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-task DNN keras model training on Tox21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook creates a single-task DNN classification model to predict toxicity (toxic / nontoxic) on the RTECS dataset, using \n",
    " - same splits as pytorch MTDNN and STDNN \n",
    " - same architecture as the pytorch STDNN on RTECS\n",
    " - FP (Morgan fingerprints) as input\n",
    " \n",
    "A separate DNN is created for each of the 12 endpoints (tasks) in Tox21. \n",
    " \n",
    "This is the trained model used within the CEM explanations scripts (cem/cem_explanations). Explanations on the prediction of this model is computed by the CEM. \n",
    "\n",
    "The model is trained on seed 122, matching the seed used for CEM explanations. \n",
    "\n",
    "Our goal on the accuracy of the model here, is to construct a keras model with the same architecture as the pytorch STDNN that can be explained by the CEM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from keras.models import model_from_json\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from rdkit.Chem.Draw import IPythonConsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "\n",
    "with HiddenPrints():\n",
    "    print(\"This will not be printed\")\n",
    "\n",
    "print(\"HiddenPrints() successful if nothing printed before this line.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This notebook experiments on performing classification prediction on Tox21 data, using the data from ngramgraph paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general and data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Required RDKit modules\n",
    "import rdkit as rd\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "import rdkit.Chem.MCS\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "# modeling\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# Graphing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import random\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed value\n",
    "seed_value = 122 #122 123 124, as used in MoleculeNet\n",
    "torch.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "torch.backends.cudnn.enabled=False\n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of bits for morgan fingerprints\n",
    "morgan_bits = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of radius for morgan fingerprints\n",
    "morgan_radius = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data \n",
    "# tox21_tasks defines each of the 12 endpoints in Tox21\n",
    "\n",
    "tox21_file  = '../../../data/datasets/tox21/raw_data/tox21.csv'\n",
    "tox21_tasks = ['NR-AR', 'NR-Aromatase', 'NR-PPAR-gamma', 'SR-HSE', \n",
    "               'NR-AR-LBD', 'NR-ER', 'SR-ARE', 'SR-MMP',\n",
    "               'NR-AhR', 'NR-ER-LBD', 'SR-ATAD5', 'SR-p53']\n",
    "\n",
    "tox21_data = pd.read_csv(tox21_file)\n",
    "print('Reading {}... {} data loaded.'.format(tox21_file, len(tox21_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [tox21_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tasks = tox21_tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load split data and compute FP (Morgan fingerprints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved tox21 train/test/valid data \n",
    "data_path = \"../../../data/datasets/tox21/split_data/seed_122/\"\n",
    "train_data=torch.load(data_path + 'train_data_tox21.pth')\n",
    "test_data=torch.load(data_path + 'test_data_tox21.pth')\n",
    "valid_data=torch.load(data_path + 'valid_data_tox21.pth')\n",
    "\n",
    "data = [train_data, test_data, valid_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# construct morgan fingerprints \n",
    "for i in range(len(data)):\n",
    "    data[i]['mol'] = [rd.Chem.MolFromSmiles(x) for x in data[i]['smiles']]\n",
    "\n",
    "    bi = [{} for _ in range(len(data[i]))]\n",
    "    data[i]['morgan'] = [AllChem.GetMorganFingerprintAsBitVect(data[i].iloc[j]['mol'], morgan_radius, nBits = morgan_bits, bitInfo=bi[j]) \n",
    "                         for j in range(len(data[i]))]\n",
    "    data[i]['bitInfo'] = bi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NA with -1 -- used to deal with missing labels, \n",
    "#                       along with Binary Cross-Entropy loss\n",
    "\n",
    "data[0] = data[0].fillna(-1)\n",
    "data[1] = data[1].fillna(-1)\n",
    "data[2] = data[2].fillna(-1)\n",
    "\n",
    "train_data = data[0]\n",
    "test_data  = data[1]\n",
    "valid_data = data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create arrays for train / test / valid sets used for DNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the RDKit explicit vectors into numpy arrays\n",
    "x_train = []\n",
    "for fp in train_data['morgan']:\n",
    "    arr = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    x_train.append(arr)\n",
    "x_train = np.array(x_train)\n",
    "\n",
    "y_train = train_data[all_tasks].astype('int').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the RDKit explicit vectors into numpy arrays\n",
    "x_test = []\n",
    "for fp in test_data['morgan']:\n",
    "    arr = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    x_test.append(arr)\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "y_test = test_data[all_tasks].astype('int').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the RDKit explicit vectors into numpy arrays\n",
    "x_valid = []\n",
    "for fp in valid_data['morgan']:\n",
    "    arr = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    x_valid.append(arr)\n",
    "x_valid = np.array(x_valid)\n",
    "\n",
    "y_valid = valid_data[all_tasks].astype('int').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.layers import Input, Dense, Dropout, Activation, BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = morgan_bits\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate models are created for each of the 12 endpoints (task)\n",
    "\n",
    "input_fp = Input(shape=(input_shape,))\n",
    "\n",
    "task_output = [None for task in all_tasks]\n",
    "for i in range(len(all_tasks)):    \n",
    "    hidden_task = Dense(1024)(input_fp)\n",
    "    hidden_task = BatchNormalization()(hidden_task)\n",
    "    hidden_task = LeakyReLU(alpha=0.05)(hidden_task)\n",
    "    \n",
    "    hidden_task = Dense(512)(hidden_task)\n",
    "    hidden_task = BatchNormalization()(hidden_task)\n",
    "    hidden_task = LeakyReLU(alpha=0.05)(hidden_task)\n",
    "\n",
    "    task_output[i] = Dense(2, activation='softmax', name=all_tasks[i])(hidden_task)\n",
    "\n",
    "deepnn = Model(input_fp, task_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnn.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the format of y_train (train set labels) to match model\n",
    "y_train_nn = [to_categorical(y_train[:,i]) for i in range(len(all_tasks))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the format of y_train (valid set labels) to match model\n",
    "y_valid_nn = [to_categorical(y_valid[:,i]) for i in range(len(all_tasks))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# specify path of saved trained model\n",
    "filepath= \"results/checkpoint.hdf5\"#\"path/checkpoint.hdf5\"\n",
    "os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "\n",
    "# saves model with the lowest validation loss\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, \n",
    "                             mode='min',  period=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# train model \n",
    "history = deepnn.fit(x_train, y_train_nn,\n",
    "                epochs = train_epoch,\n",
    "                batch_size = batch,\n",
    "                shuffle = True,\n",
    "                validation_data=(x_valid, y_valid_nn),\n",
    "                callbacks = [checkpoint],\n",
    "                verbose=1\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load trained model from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best by minimum valid loss\n",
    "deepnn.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### See Test set performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = MTDNN.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "valid_datapoints = y_test[:,i] >= 0\n",
    "y_test_task = y_test[valid_datapoints,i] \n",
    "y_test_pred_task = y_test_pred[i][valid_datapoints,1]\n",
    "\n",
    "acc = accuracy_score(y_test_task, np.round(y_test_pred_task))\n",
    "print('Accuracy for DNN on Morgan Fingerprint:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Computes: auc, true positive (tp), true negative (tn), false positive (fp), false negative (fn)\n",
    "### For each model predicting a task within the 12 possible tasks for Tox21 \n",
    "\n",
    "results = {}\n",
    "# Test AUC\n",
    "for i in range(len(all_tasks)):\n",
    "    \n",
    "    valid_datapoints = y_test[:,i] >= 0\n",
    "    y_test_task = y_test[valid_datapoints,i] \n",
    "    y_test_pred_task = y_test_pred[i][valid_datapoints,1]\n",
    "    \n",
    "    acc = accuracy_score(y_test_task, np.round(y_test_pred_task))\n",
    "    print('Accuracy for MTDNN on Morgan Fingerprint:', acc)\n",
    "    \n",
    "    bacc = sk.metrics.balanced_accuracy_score(y_test_task, np.round(y_test_pred_task))\n",
    "\n",
    "    f1 = f1_score(y_test_task, np.round(y_test_pred_task), pos_label=1)\n",
    "    print('F1 for MTDNN on Morgan Fingerprint:', f1)\n",
    "\n",
    "    cfm = sk.metrics.confusion_matrix(y_test_task, np.round(y_test_pred_task))#, normalize='true')\n",
    "#     print('Confusion Matrix for deepnn on Morgan Fingerprint:\\n', cfm)\n",
    "    cfm = cfm.astype('float') / cfm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    tn, fp, fn, tp = cfm.ravel()\n",
    "    pr = tp / (tp + fp)\n",
    "    rc = tp / (tp + fn)\n",
    "    print(' True Positive:', tp)\n",
    "    print(' True Negative:', tn)\n",
    "    print('False Positive:', fp)\n",
    "    print('False Negative:', fn)\n",
    "    \n",
    "    \n",
    "    auc = roc_auc_score(y_test_task, y_test_pred_task)\n",
    "    print('Test ROC AUC ({}):'.format(all_tasks[i]), auc)\n",
    "    \n",
    "    results[all_tasks[i]] = [auc, acc, bacc, tn, tp, pr, rc, f1]\n",
    "\n",
    "    fpr, tpr, threshold = sk.metrics.roc_curve(y_test_task, y_test_pred_task)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Returns performance metrics for each model prediciting a specific task within the 12 possible tasks for Tox21 \n",
    "\n",
    "print('Task'.ljust(10), '\\t', '  AUC ', ' ACC ', ' BACC ', ' TN  ', ' TP  ', ' PR  ', ' RC  ', ' F1  ')\n",
    "for task, auc in results.items():\n",
    "    print(task.ljust(10), '\\t', np.round(auc,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
