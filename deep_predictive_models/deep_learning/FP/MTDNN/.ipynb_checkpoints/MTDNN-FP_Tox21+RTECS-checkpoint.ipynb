{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This notebook creates MTDNN-FP (pytorch) for classification prediction on Tox21 and RTECS\n",
    "\n",
    "Using split data already saved.\n",
    "\n",
    "RTECS dataset has been commented out. \n",
    "\n",
    "Notebook shows results for seed = 124, but we also ran on seed 122, 123. \n",
    "\n",
    "Before use define desired pathways to save models,:\n",
    "- path variable, in \"Create checkpoint\" section for models\n",
    "- writer variable, in \"Train the neural network model\" section for tensorboard summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general and data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Required RDKit modules\n",
    "import rdkit as rd\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "# modeling\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Graphing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ensure runs on GPU\n",
    "import tensorflow as tf\n",
    "import datetime, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed value\n",
    "seed_value = 124 #122 123 124, as used in MoleculeNet\n",
    "torch.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "torch.backends.cudnn.enabled=False\n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of bits for morgan fingerprints\n",
    "morgan_bits = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of radius for morgan fingerprints\n",
    "morgan_radius = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch = 50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 512 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tox21_file  = '../../../../data/datasets/tox21/raw_data/tox21.csv'\n",
    "tox21_tasks = ['NR-AR', 'NR-Aromatase', 'NR-PPAR-gamma', 'SR-HSE', \n",
    "               'NR-AR-LBD', 'NR-ER', 'SR-ARE', 'SR-MMP',\n",
    "               'NR-AhR', 'NR-ER-LBD', 'SR-ATAD5', 'SR-p53']\n",
    "\n",
    "tox21_data = pd.read_csv(tox21_file)\n",
    "print('Reading {}... {} data loaded.'.format(tox21_file, len(tox21_data)))\n",
    "tox21_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_oral_file = # cannot provide\n",
    "\n",
    "a_oral_data = pd.read_csv(a_oral_file)\n",
    "a_oral_tasks = ['toxic_a_oral'] \n",
    "a_oral_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting all tasks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [tox21_data, a_oral_data] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tasks = tox21_tasks + a_oral_tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved tox21 train/test/valid data \n",
    "data_path = \"../../../../data/datasets/tox21/split_data/seed_124/\"\n",
    "train_data=torch.load(data_path + 'train_data_tox21.pth')\n",
    "test_data=torch.load(data_path + 'test_data_tox21.pth')\n",
    "valid_data=torch.load(data_path + 'valid_data_tox21.pth')\n",
    "\n",
    "# load saved rtecs train/test/valid data \n",
    "data_path = # cannot provide\n",
    "train_data_rtecs=torch.load(data_path + 'train_data_rtecs.pth')\n",
    "test_data_rtecs=torch.load(data_path + 'test_data_rtecs.pth')\n",
    "valid_data_rtecs=torch.load(data_path + 'valid_data_rtecs.pth')\n",
    "\n",
    "# merge the Tox21 with RTECS set datasets\n",
    "train_data = train_data.merge(train_data_rtecs, how='outer', on='smiles')\n",
    "test_data  = test_data.merge(test_data_rtecs, how='outer', on='smiles')\n",
    "valid_data  = valid_data.merge(valid_data_rtecs, how='outer', on='smiles')\n",
    "\n",
    "\n",
    "data = [train_data, test_data, valid_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of examples, train: \" + str(data[0].shape[0]))\n",
    "print(\"Total number of examples, test: \" + str(data[1].shape[0]))\n",
    "print(\"Total number of examples, valid: \" + str(data[2].shape[0]))\n",
    "print(\"Total number of examples, train+test+valid: \" + str(data[0].shape[0] + data[1].shape[0] + data[2].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Construct Morgan Fingerprints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# construct morgan fingerprints \n",
    "for i in range(len(data)):\n",
    "    data[i]['mol'] = [rd.Chem.MolFromSmiles(x) for x in data[i]['smiles']]\n",
    "\n",
    "    bi = [{} for _ in range(len(data[i]))]\n",
    "    data[i]['morgan'] = [AllChem.GetMorganFingerprintAsBitVect(data[i].iloc[j]['mol'], morgan_radius, nBits = morgan_bits, bitInfo=bi[j]) \n",
    "                         for j in range(len(data[i]))]\n",
    "    data[i]['bitInfo'] = bi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create train, test, valid sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NA with -1 -- used to deal with missing labels, \n",
    "#                       along with Binary Cross-Entropy loss\n",
    "data[0] = data[0].fillna(-1)\n",
    "data[1] = data[1].fillna(-1)\n",
    "data[2] = data[2].fillna(-1)\n",
    "train_data = data[0]\n",
    "test_data  = data[1]\n",
    "valid_data = data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Arrays for train / test / valid sets used for DNN \n",
    "# convert the RDKit explicit vectors into numpy arrays\n",
    "x_train = []\n",
    "for fp in train_data['morgan']:\n",
    "    arr = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    x_train.append(arr)\n",
    "x_train = np.array(x_train)\n",
    "x_train = x_train - 0.5\n",
    "\n",
    "y_train = train_data[all_tasks].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the RDKit explicit vectors into numpy arrays\n",
    "x_test = []\n",
    "for fp in test_data['morgan']:\n",
    "    arr = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    x_test.append(arr)\n",
    "x_test = np.array(x_test)\n",
    "x_test = x_test - 0.5\n",
    "\n",
    "y_test = test_data[all_tasks].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the RDKit explicit vectors into numpy arrays\n",
    "x_valid = []\n",
    "for fp in valid_data['morgan']:\n",
    "    arr = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    x_valid.append(arr)\n",
    "x_valid = np.array(x_valid)\n",
    "x_valid = x_valid - 0.5\n",
    "\n",
    "y_valid = valid_data[all_tasks].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of data points per class\n",
    "N_train = np.sum(y_train >= 0, 0)\n",
    "N_test  = np.sum(y_test >= 0, 0)\n",
    "N_valid  = np.sum(y_valid >= 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Deep Neural Network (pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data for pytorch\n",
    "x_train_torch = x_train.astype(np.float32)\n",
    "y_train_torch = y_train.astype(np.float32)\n",
    "\n",
    "x_test_torch = x_test.astype(np.float32)\n",
    "y_test_torch = y_test.astype(np.float32)\n",
    "\n",
    "x_valid_torch = x_valid.astype(np.float32)\n",
    "y_valid_torch = y_valid.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train_torch.shape[1]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for MTDNN data\n",
    "class MTDNNData(Dataset):\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = MTDNNData(x_train_torch, y_train_torch)\n",
    "training_generator = DataLoader(training_set, batch_size=batch, shuffle=True)\n",
    "\n",
    "testing_set = MTDNNData(x_test_torch, y_test_torch)\n",
    "testing_generator = DataLoader(testing_set, batch_size=len(testing_set), shuffle=False)\n",
    "\n",
    "valid_set = MTDNNData(x_valid_torch, y_valid_torch)\n",
    "valid_generator = DataLoader(valid_set, batch_size=len(valid_set), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MTDNN Model class\n",
    "### 2 shared layers for all tasks, followed by 2 layers for each separate task\n",
    "\n",
    "class MTDNN(torch.nn.Module):\n",
    "    def __init__(self, input_shape, all_tasks):\n",
    "        super(MTDNN, self).__init__()\n",
    "\n",
    "        # neural network layers\n",
    "        self.shared_1 = torch.nn.Linear(input_shape, 2048)\n",
    "        self.batchnorm_1 = torch.nn.BatchNorm1d(2048)\n",
    "        \n",
    "        self.shared_2 = torch.nn.Linear(2048, 1024)\n",
    "        self.batchnorm_2 = torch.nn.BatchNorm1d(1024)\n",
    "        \n",
    "        self.hidden_3 = torch.nn.ModuleList([torch.nn.Linear(1024, 512) for task in all_tasks])\n",
    "        self.batchnorm_3 = torch.nn.ModuleList([torch.nn.BatchNorm1d(512) for task in all_tasks])\n",
    "        \n",
    "        self.hidden_4 = torch.nn.ModuleList([torch.nn.Linear(512, 256) for task in all_tasks])\n",
    "        self.batchnorm_4 = torch.nn.ModuleList([torch.nn.BatchNorm1d(256) for task in all_tasks])\n",
    "        \n",
    "        self.output   = torch.nn.ModuleList([torch.nn.Linear(256, 1) for task in all_tasks])\n",
    "        \n",
    "        # function for leaky ReLU\n",
    "        self.leakyReLU = torch.nn.LeakyReLU(0.05)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # shared layers\n",
    "        x = self.shared_1(x)\n",
    "        x = self.batchnorm_1(x)\n",
    "        x = self.leakyReLU(x)\n",
    "        \n",
    "        x = self.shared_2(x)\n",
    "        x = self.batchnorm_2(x)\n",
    "        x = self.leakyReLU(x)\n",
    "        \n",
    "        x_task = [None for i in range(len(self.output))]  # initialize\n",
    "        for task in range(len(self.output)):\n",
    "            x_task[task] = self.hidden_3[task](x)\n",
    "            x_task[task] = self.batchnorm_3[task](x_task[task])\n",
    "            x_task[task] = self.leakyReLU(x_task[task])\n",
    "            \n",
    "            x_task[task] = self.hidden_4[task](x_task[task])\n",
    "            x_task[task] = self.batchnorm_4[task](x_task[task])\n",
    "            x_task[task] = self.leakyReLU(x_task[task])\n",
    "            \n",
    "            x_task[task] = self.output[task](x_task[task])\n",
    "            x_task[task] = torch.sigmoid(x_task[task])\n",
    "        \n",
    "        y_pred = x_task\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "model = MTDNN(input_shape, all_tasks).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create checkpoint - saving and loading best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method from : https://gist.github.com/vsay01/45dfced69687077be53dbdd4987b6b17\n",
    "\n",
    "import shutil\n",
    "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
    "    \"\"\"\n",
    "    state: checkpoint we want to save\n",
    "    is_best: is this the best checkpoint; min validation loss\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    best_model_path: path to save best model\n",
    "    \"\"\"\n",
    "    f_path = checkpoint_path\n",
    "    # save checkpoint data to the path given, checkpoint_path\n",
    "    torch.save(state, f_path)\n",
    "    # if it is a best model, min validation loss\n",
    "    if is_best:\n",
    "        best_fpath = best_model_path\n",
    "        # copy that checkpoint file to best path given, best_model_path\n",
    "        shutil.copyfile(f_path, best_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckp(checkpoint_fpath, input_model, optimizer):\n",
    "    \"\"\"\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    model: model that we want to load checkpoint parameters into       \n",
    "    optimizer: optimizer we defined in previous training\n",
    "    \"\"\"\n",
    "    # load check point\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    # initialize state_dict from checkpoint to model\n",
    "    input_model.load_state_dict(checkpoint['state_dict'])\n",
    "    # initialize optimizer from checkpoint to optimizer\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
    "    train_loss_min = checkpoint['train_loss_min']\n",
    "    # return model, optimizer, epoch value, min validation loss \n",
    "    return model, optimizer, checkpoint['epoch'], train_loss_min.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p #specify path to save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = #specify path to save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Pathways to save models \n",
    "checkpoint_path = path + '/current_checkpoint.pt'\n",
    "\n",
    "#Path to saved model when train_epoch_loss <= train_loss_min\n",
    "bestmodel_path = path + '/best_model.pt'\n",
    "\n",
    "#Path to saved model at minimum valid loss\n",
    "bestmodel_byvalid = path + '/best_model_by_valid.pt'\n",
    "\n",
    "#Path to saved  when train_epoch_loss >= val_epoch_loss\n",
    "bestmodel_byvalid_crossed = path + '/best_model_by_valid-crossed.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train the neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Define the desired pathway\n",
    "writer = SummaryWriter('define-pathway-to-save/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "##################### With Tensorboard ######################\n",
    "loss_history=[]  \n",
    "correct_history=[]  \n",
    "val_loss_history=[]  \n",
    "val_correct_history=[] \n",
    "train_loss_min = np.Inf\n",
    "val_loss_min = np.Inf\n",
    "\n",
    "\n",
    "# Training\n",
    "for e in range(train_epoch):\n",
    "    \n",
    "    model.train()\n",
    "    # keep track of the loss over an epoch\n",
    "    running_train_loss = 0\n",
    "    running_valid_loss = 0\n",
    "    running_train_correct = 0\n",
    "    running_val_correct = 0\n",
    "    y_train_true = []\n",
    "    y_train_pred = []\n",
    "    y_valid_true = []\n",
    "    y_valid_pred = []\n",
    "    batch = 0\n",
    "    for x_batch, y_batch in training_generator:\n",
    "        batch += 1\n",
    "        if torch.cuda.is_available():\n",
    "            x_batch, y_batch = x_batch.cuda(), y_batch.cuda() \n",
    "        \n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        y_pred = model(x_batch)  # for all tasks\n",
    "        \n",
    "        # Compute loss over all tasks\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        y_train_true_task = []\n",
    "        y_train_pred_task = []\n",
    "        for i in range(len(all_tasks)):\n",
    "            y_batch_task = y_batch[:,i]\n",
    "            y_pred_task  = y_pred[i][:,0] #check if predictions na\n",
    "            \n",
    "            # compute loss for labels that are not NA\n",
    "            indice_valid = y_batch_task >= 0\n",
    "            loss_task = criterion(y_pred_task[indice_valid], y_batch_task[indice_valid]) / N_train[i]\n",
    "            \n",
    "            loss += loss_task\n",
    "\n",
    "            pred_train = np.round(y_pred_task[indice_valid].detach().cpu().numpy())\n",
    "            target_train = y_batch_task[indice_valid].float()\n",
    "            y_train_true.extend(target_train.tolist()) \n",
    "            y_train_pred.extend(pred_train.reshape(-1).tolist())\n",
    "\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        writer.add_scalar(\"Accuracy/train\", loss, batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        # sum up the losses from each batch\n",
    "        running_train_loss += loss.item()\n",
    "        writer.add_scalar(\"Loss/train\", running_train_loss, e)\n",
    "        \n",
    "    else:\n",
    "        with torch.no_grad():    \n",
    "        ## evaluation part \n",
    "            model.eval()\n",
    "            for val_x_batch, val_y_batch in valid_generator:\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    val_x_batch, val_y_batch = val_x_batch.cuda(), val_y_batch.cuda() \n",
    "                \n",
    "                val_output = model(val_x_batch)\n",
    "\n",
    "                ## 2. loss calculation over all tasks \n",
    "                val_loss = 0\n",
    "                val_correct = 0\n",
    "                y_valid_true_task = []\n",
    "                y_valid_pred_task = []\n",
    "                for i in range(len(all_tasks)):\n",
    "                    val_y_batch_task = val_y_batch[:,i]\n",
    "                    val_output_task  = val_output[i][:,0]\n",
    "\n",
    "                    # compute loss for labels that are not NA\n",
    "                    indice_valid = val_y_batch_task >= 0\n",
    "                    val_loss_task = criterion(val_output_task[indice_valid], val_y_batch_task[indice_valid]) / N_valid[i]\n",
    "\n",
    "                    val_loss += val_loss_task\n",
    "                    \n",
    "                    pred_valid = np.round(val_output_task[indice_valid].detach().cpu().numpy())\n",
    "                    target_valid = val_y_batch_task[indice_valid].float()\n",
    "                    y_valid_true.extend(target_valid.tolist()) \n",
    "                    y_valid_pred.extend(pred_valid.reshape(-1).tolist())\n",
    "                \n",
    "                #writer.add_scalar(\"Loss/valid\", val_loss, batch)\n",
    "\n",
    "                running_valid_loss+=val_loss.item()\n",
    "                writer.add_scalar(\"Loss/valid\", running_valid_loss, e)\n",
    "        \n",
    "        #epoch loss\n",
    "        train_epoch_loss=np.mean(running_train_loss)\n",
    "        val_epoch_loss=np.mean(running_valid_loss)  \n",
    "       \n",
    "        #epoch accuracy     \n",
    "        train_epoch_acc = accuracy_score(y_train_true,y_train_pred)\n",
    "        val_epoch_acc = accuracy_score(y_valid_true,y_valid_pred)\n",
    "        \n",
    "        #history\n",
    "        loss_history.append(train_epoch_loss)  \n",
    "        correct_history.append(train_epoch_acc)\n",
    "        val_loss_history.append(val_epoch_loss)  \n",
    "        val_correct_history.append(val_epoch_acc)  \n",
    "        \n",
    "        print(\"Epoch:\", e, \"Training Loss:\", train_epoch_loss, \"Valid Loss:\", val_epoch_loss)\n",
    "        print(\"Training Acc:\", train_epoch_acc, \"Valid Acc:\", val_epoch_acc)\n",
    "        \n",
    "        # create checkpoint variable and add important data\n",
    "        checkpoint = {\n",
    "            'epoch': e + 1,\n",
    "            'train_loss_min': train_epoch_loss,\n",
    "            'val_loss_min': val_epoch_loss, \n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "        \n",
    "        # save checkpoint\n",
    "        save_ckp(checkpoint, False, checkpoint_path, bestmodel_path)\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if train_epoch_loss <= train_loss_min:\n",
    "            print('Training loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(train_loss_min,train_epoch_loss))\n",
    "            # save checkpoint as best model\n",
    "            save_ckp(checkpoint, True, checkpoint_path, bestmodel_path)\n",
    "            train_loss_min = train_epoch_loss\n",
    "            \n",
    "        if train_epoch_loss >= val_epoch_loss:\n",
    "            print('Training loss greater than validation loss ({:.6f} --> {:.6f}).  Saving model ...'.format(train_epoch_loss,val_epoch_loss))\n",
    "            # save checkpoint as best model\n",
    "            save_ckp(checkpoint, True, checkpoint_path, bestmodel_byvalid_crossed)\n",
    "            train_loss_min = train_epoch_loss\n",
    "            \n",
    "        if val_epoch_loss <= val_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}). Saving model ...'.format(val_loss_min,val_epoch_loss))\n",
    "            # save checkpoint as best model\n",
    "            save_ckp(checkpoint, True, checkpoint_path, bestmodel_byvalid)\n",
    "            val_loss_min = val_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads model at lowest validation loss \n",
    "loaded_model, optimizer, start_epoch, train_loss_min = load_ckp(bestmodel_byvalid, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model = \", loaded_model)\n",
    "print(\"optimizer = \", optimizer)\n",
    "print(\"start_epoch = \", start_epoch)\n",
    "print(\"train_loss_min = \", train_loss_min)\n",
    "print(\"train_loss_min = {:.6f}\".format(train_loss_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate on test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print test loss\n",
    "for x_test_torch, y_test_torch in testing_generator:\n",
    "    y_test_pred = loaded_model.eval().to(device).cpu()(x_test_torch)\n",
    "    \n",
    "    # Compute loss over all tasks\n",
    "    loss = 0\n",
    "    for i in range(len(all_tasks)):\n",
    "        y_test_task = y_test_torch[:,i]\n",
    "        y_pred_task  = y_test_pred[i][:,0]\n",
    "\n",
    "        # compute loss for labels that are not NA\n",
    "        indice_valid = y_test_task >= 0\n",
    "        loss_task = criterion(y_pred_task[indice_valid], y_test_task[indice_valid]) / N_test[i]\n",
    "\n",
    "        loss += loss_task\n",
    "    \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "# Collects performance metrics for all tasks on test set\n",
    "for i in range(len(all_tasks)):\n",
    "    \n",
    "    valid_datapoints = y_test[:,i] >= 0\n",
    "    y_test_task = y_test[valid_datapoints,i] \n",
    "    y_test_pred_task = y_test_pred[i].detach().numpy()[valid_datapoints,0]\n",
    "    \n",
    "    acc = accuracy_score(y_test_task, np.round(y_test_pred_task))\n",
    "    print('Accuracy for MTDNN on Morgan Fingerprint:', acc)\n",
    "    \n",
    "    bacc = sk.metrics.balanced_accuracy_score(y_test_task, np.round(y_test_pred_task))\n",
    "\n",
    "    f1 = f1_score(y_test_task, np.round(y_test_pred_task), pos_label=1)\n",
    "    print('F1 for MTDNN on Morgan Fingerprint:', f1)\n",
    "\n",
    "    cfm = sk.metrics.confusion_matrix(y_test_task, np.round(y_test_pred_task))\n",
    "    cfm = cfm.astype('float') / cfm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    tn, fp, fn, tp = cfm.ravel()\n",
    "    pr = tp / (tp + fp)\n",
    "    rc = tp / (tp + fn)\n",
    "    print(' True Positive:', tp)\n",
    "    print(' True Negative:', tn)\n",
    "    print('False Positive:', fp)\n",
    "    print('False Negative:', fn)\n",
    "    \n",
    "    \n",
    "    auc = roc_auc_score(y_test_task, y_test_pred_task)\n",
    "    print('Test ROC AUC ({}):'.format(all_tasks[i]), auc)\n",
    "    \n",
    "    results[all_tasks[i]] = [auc, acc, bacc, tn, tp, pr, rc, f1]\n",
    "\n",
    "    fpr, tpr, threshold = sk.metrics.roc_curve(y_test_task, y_test_pred_task)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Task'.ljust(10), '\\t', '  AUC ', ' ACC ', ' BACC ', ' TN  ', ' TP  ', ' PR  ', ' RC  ', ' F1  ')\n",
    "for task, auc in results.items():\n",
    "    print(task.ljust(10), '\\t', np.round(auc,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### See Valid set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print test loss\n",
    "for x_valid_torch, y_valid_torch in valid_generator:\n",
    "    y_valid_pred = model.eval().to(device).cpu()(x_valid_torch)\n",
    "    \n",
    "    # Compute loss over all tasks\n",
    "    loss = 0\n",
    "    for i in range(len(all_tasks)):\n",
    "        y_test_task = y_valid_torch[:,i]\n",
    "        y_pred_task  = y_valid_pred[i][:,0]\n",
    "\n",
    "        # compute loss for labels that are not NA\n",
    "        indice_valid = y_test_task >= 0\n",
    "        loss_task = criterion(y_pred_task[indice_valid], y_test_task[indice_valid]) / N_test[i]\n",
    "\n",
    "        loss += loss_task\n",
    "    \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_valid = {}\n",
    "# Collects performance metrics for all tasks on Valid set\n",
    "for i in range(len(all_tasks)):\n",
    "    \n",
    "    valid_datapoints = y_valid[:,i] >= 0\n",
    "    y_valid_task = y_valid[valid_datapoints,i] \n",
    "    y_valid_pred_task = y_valid_pred[i].detach().numpy()[valid_datapoints,0]\n",
    "    \n",
    "    \n",
    "    acc = accuracy_score(y_valid_task, np.round(y_valid_pred_task))\n",
    "    print('Accuracy for deepnn on Morgan Fingerprint:', acc)\n",
    "    \n",
    "    bacc = sk.metrics.balanced_accuracy_score(y_valid_task, np.round(y_valid_pred_task))\n",
    "\n",
    "    f1 = f1_score(y_valid_task, np.round(y_valid_pred_task), pos_label=1)\n",
    "    print('F1 for deepnn on Morgan Fingerprint:', f1)\n",
    "\n",
    "    cfm = sk.metrics.confusion_matrix(y_valid_task, np.round(y_valid_pred_task))\n",
    "    cfm = cfm.astype('float') / cfm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    print('Confusion Matrix for deepnn on Morgan Fingerprint:\\n', cfm)\n",
    "\n",
    "    tn, fp, fn, tp = cfm.ravel()\n",
    "    pr = tp / (tp + fp)\n",
    "    rc = tp / (tp + fn)\n",
    "    print(' True Positive:', tp)\n",
    "    print(' True Negative:', tn)\n",
    "    print('False Positive:', fp)\n",
    "    print('False Negative:', fn)\n",
    "    \n",
    "    \n",
    "    auc = roc_auc_score(y_valid_task, y_valid_pred_task)\n",
    "    print('Test ROC AUC ({}):'.format(all_tasks[i]), auc)\n",
    "    \n",
    "    results_valid[all_tasks[i]] = [auc, acc, bacc, tn, tp, pr, rc, f1]\n",
    "\n",
    "    fpr, tpr, threshold = sk.metrics.roc_curve(y_valid_task, y_valid_pred_task)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Task'.ljust(10), '\\t', '  AUC ', ' ACC ', ' BACC ', ' TN  ', ' TP  ', ' PR  ', ' RC  ', ' F1  ')\n",
    "for task, auc in results_valid.items():\n",
    "    print(task.ljust(10), '\\t', np.round(auc,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
