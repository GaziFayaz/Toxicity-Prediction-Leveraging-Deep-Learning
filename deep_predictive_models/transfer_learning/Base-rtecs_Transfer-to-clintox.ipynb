{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This notebook creates Transfer Learning (TL) experiment, with base model trained on RTECS, transferred to predict on ClinTox\n",
    "\n",
    "Using split data already saved.\n",
    "\n",
    "RTECS dataset has been commented out. \n",
    "\n",
    "Notebook shows results for seed = 124, but we also ran on seed 122, 123. \n",
    "\n",
    "To create TL model. Base model was trained with a MTDNN that had two shared layers and two separate layers for all tasks. Then the two shared layers were extracted and frozen, and two additional layers training on ClinTox for 1 epoch was added. \n",
    "\n",
    "Before use define desired pathways to save models,:\n",
    "- path variable, in \"Create checkpoint\" section for models\n",
    "- writer variable, in \"Train the neural network model\" section for tensorboard summary\n",
    "- base_modelpath variable, in \"Save base model\" section "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general and data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Required RDKit modules\n",
    "import rdkit as rd\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "# modeling\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# Graphing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ensure runs on GPU\n",
    "import tensorflow as tf\n",
    "import datetime, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed value\n",
    "seed_value = 124 #122 123 124, as used in MoleculeNet\n",
    "torch.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "torch.backends.cudnn.enabled=False\n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of bits for morgan fingerprints\n",
    "morgan_bits = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of radius for morgan fingerprints\n",
    "morgan_radius = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No limit on max columns displayed in a dataframe\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clintox_file = '../../data/datasets/clintox/raw_data/clintox.csv'\n",
    "clintox_task = ['CT_TOX']\n",
    "\n",
    "clintox_data = pd.read_csv(clintox_file)\n",
    "print('Reading {}... {} data loaded.'.format(clintox_file, len(clintox_data)))\n",
    "clintox_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_oral_file = # cannot provide \n",
    "\n",
    "a_oral_data = pd.read_csv(a_oral_file)\n",
    "a_oral_tasks = ['toxic_a_oral'] \n",
    "a_oral_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = \"blue\"> Create and train base model </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting all tasks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [a_oral_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tasks = a_oral_tasks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## ONLY RTECS ########\n",
    "# load saved rtecs train/test/valid data \n",
    "data_path = # cannot provide \n",
    "train_data=torch.load(data_path + 'train_data_rtecs.pth')\n",
    "test_data=torch.load(data_path + 'test_data_rtecs.pth')\n",
    "valid_data=torch.load(data_path + 'valid_data_rtecs.pth')\n",
    "\n",
    "data = [train_data, test_data, valid_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of examples, train: \" + str(data[0].shape[0]))\n",
    "print(\"Total number of examples, test: \" + str(data[1].shape[0]))\n",
    "print(\"Total number of examples, valid: \" + str(data[2].shape[0]))\n",
    "print(\"Total number of examples, train+test+valid: \" + str(data[0].shape[0] + data[1].shape[0] + data[2].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Construct Morgan Fingerprints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# construct morgan fingerprints \n",
    "for i in range(len(data)):\n",
    "    data[i]['mol'] = [rd.Chem.MolFromSmiles(x) for x in data[i]['smiles']]\n",
    "\n",
    "    bi = [{} for _ in range(len(data[i]))]\n",
    "    data[i]['morgan'] = [AllChem.GetMorganFingerprintAsBitVect(data[i].iloc[j]['mol'], morgan_radius, nBits = morgan_bits, bitInfo=bi[j]) \n",
    "                         for j in range(len(data[i]))]\n",
    "    data[i]['bitInfo'] = bi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create train, valid and test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_data, test_data, valid_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NA with -1 -- used to deal with missing labels, \n",
    "#                       along with Binary Cross-Entropy loss\n",
    "data[0] = data[0].fillna(-1)\n",
    "data[1] = data[1].fillna(-1)\n",
    "data[2] = data[2].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[0]\n",
    "test_data  = data[1]\n",
    "valid_data = data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Arrays for train / test / valid sets used for DNN \n",
    "# convert the RDKit explicit vectors into numpy arrays\n",
    "x_train = []\n",
    "for fp in train_data['morgan']:\n",
    "    arr = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    x_train.append(arr)\n",
    "x_train = np.array(x_train)\n",
    "x_train = x_train - 0.5\n",
    "\n",
    "y_train = train_data[all_tasks].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the RDKit explicit vectors into numpy arrays\n",
    "x_test = []\n",
    "for fp in test_data['morgan']:\n",
    "    arr = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    x_test.append(arr)\n",
    "x_test = np.array(x_test)\n",
    "x_test = x_test - 0.5\n",
    "\n",
    "y_test = test_data[all_tasks].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the RDKit explicit vectors into numpy arrays\n",
    "x_valid = []\n",
    "for fp in valid_data['morgan']:\n",
    "    arr = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    x_valid.append(arr)\n",
    "x_valid = np.array(x_valid)\n",
    "x_valid = x_valid - 0.5\n",
    "\n",
    "y_valid = valid_data[all_tasks].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of data points per class\n",
    "N_train = np.sum(y_train >= 0, 0)\n",
    "N_test  = np.sum(y_test >= 0, 0)\n",
    "N_valid  = np.sum(y_valid >= 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Neural Network (pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data for pytorch\n",
    "x_train_torch = x_train.astype(np.float32)\n",
    "y_train_torch = y_train.astype(np.float32)\n",
    "\n",
    "x_test_torch = x_test.astype(np.float32)\n",
    "y_test_torch = y_test.astype(np.float32)\n",
    "\n",
    "x_valid_torch = x_valid.astype(np.float32)\n",
    "y_valid_torch = y_valid.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train_torch.shape[1]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for MTDNN data\n",
    "class MTDNNData(Dataset):\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = MTDNNData(x_train_torch, y_train_torch)\n",
    "training_generator = DataLoader(training_set, batch_size=batch, shuffle=True)\n",
    "\n",
    "testing_set = MTDNNData(x_test_torch, y_test_torch)\n",
    "testing_generator = DataLoader(testing_set, batch_size=len(testing_set), shuffle=False)\n",
    "\n",
    "valid_set = MTDNNData(x_valid_torch, y_valid_torch)\n",
    "valid_generator = DataLoader(valid_set, batch_size=len(valid_set), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MTDNN Model class\n",
    "### 2 shared layers for all tasks, followed by 2 layers for each separate task (1 in RTECS)\n",
    "\n",
    "class MTDNN(torch.nn.Module):\n",
    "    def __init__(self, input_shape, all_tasks):\n",
    "        super(MTDNN, self).__init__()\n",
    "\n",
    "        # neural network layers\n",
    "        self.shared_1 = torch.nn.Linear(input_shape, 2048)\n",
    "        self.batchnorm_1 = torch.nn.BatchNorm1d(2048)\n",
    "        \n",
    "        self.shared_2 = torch.nn.Linear(2048, 1024)\n",
    "        self.batchnorm_2 = torch.nn.BatchNorm1d(1024)\n",
    "        \n",
    "        self.hidden_3 = torch.nn.ModuleList([torch.nn.Linear(1024, 512) for task in all_tasks])\n",
    "        self.batchnorm_3 = torch.nn.ModuleList([torch.nn.BatchNorm1d(512) for task in all_tasks])\n",
    "        \n",
    "        self.hidden_4 = torch.nn.ModuleList([torch.nn.Linear(512, 256) for task in all_tasks])\n",
    "        self.batchnorm_4 = torch.nn.ModuleList([torch.nn.BatchNorm1d(256) for task in all_tasks])\n",
    "        \n",
    "        self.output   = torch.nn.ModuleList([torch.nn.Linear(256, 1) for task in all_tasks])\n",
    "        \n",
    "        # function for leaky ReLU\n",
    "        self.leakyReLU = torch.nn.LeakyReLU(0.05)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # shared layers\n",
    "        x = self.shared_1(x)\n",
    "        x = self.batchnorm_1(x)\n",
    "        x = self.leakyReLU(x)\n",
    "        \n",
    "        x = self.shared_2(x)\n",
    "        x = self.batchnorm_2(x)\n",
    "        x = self.leakyReLU(x)\n",
    "        \n",
    "        x_task = [None for i in range(len(self.output))]  # initialize\n",
    "        for task in range(len(self.output)):\n",
    "            x_task[task] = self.hidden_3[task](x)\n",
    "            x_task[task] = self.batchnorm_3[task](x_task[task])\n",
    "            x_task[task] = self.leakyReLU(x_task[task])\n",
    "            \n",
    "            x_task[task] = self.hidden_4[task](x_task[task])\n",
    "            x_task[task] = self.batchnorm_4[task](x_task[task])\n",
    "            x_task[task] = self.leakyReLU(x_task[task])\n",
    "            \n",
    "            x_task[task] = self.output[task](x_task[task])\n",
    "            x_task[task] = torch.sigmoid(x_task[task])\n",
    "        \n",
    "        y_pred = x_task\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "model = MTDNN(input_shape, all_tasks).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create checkpoint - saving and loading best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method from : https://gist.github.com/vsay01/45dfced69687077be53dbdd4987b6b17\n",
    "\n",
    "import shutil\n",
    "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
    "    \"\"\"\n",
    "    state: checkpoint we want to save\n",
    "    is_best: is this the best checkpoint; min validation loss\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    best_model_path: path to save best model\n",
    "    \"\"\"\n",
    "    f_path = checkpoint_path\n",
    "    # save checkpoint data to the path given, checkpoint_path\n",
    "    torch.save(state, f_path)\n",
    "    # if it is a best model, min validation loss\n",
    "    if is_best:\n",
    "        best_fpath = best_model_path\n",
    "        # copy that checkpoint file to best path given, best_model_path\n",
    "        shutil.copyfile(f_path, best_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckp(checkpoint_fpath, input_model, optimizer):\n",
    "    \"\"\"\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    model: model that we want to load checkpoint parameters into       \n",
    "    optimizer: optimizer we defined in previous training\n",
    "    \"\"\"\n",
    "    # load check point\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    # initialize state_dict from checkpoint to model\n",
    "    input_model.load_state_dict(checkpoint['state_dict'])\n",
    "    # initialize optimizer from checkpoint to optimizer\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
    "    train_loss_min = checkpoint['train_loss_min']\n",
    "    # return model, optimizer, epoch value, min validation loss \n",
    "    return model, optimizer, checkpoint['epoch'], train_loss_min.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = # define pathway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Pathways to save models \n",
    "checkpoint_path = path + '/current_checkpoint.pt'\n",
    "\n",
    "#Path to saved model when train_epoch_loss <= train_loss_min\n",
    "bestmodel_path = path + '/best_model.pt'  \n",
    "\n",
    "#Path to saved model at minimum valid loss\n",
    "bestmodel_byvalid = path + '/best_model_by_valid.pt' \n",
    "\n",
    "#Path to saved  when train_epoch_loss >= val_epoch_loss\n",
    "bestmodel_byvalid_crossed = path + '/best_model_by_valid-crossed.pt'   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train the neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Define the desired pathway\n",
    "writer = SummaryWriter('define-pathway/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "##################### With Tensorboard ######################\n",
    "loss_history=[]  \n",
    "correct_history=[]  \n",
    "val_loss_history=[]  \n",
    "val_correct_history=[] \n",
    "train_loss_min = np.Inf\n",
    "val_loss_min = np.Inf\n",
    "\n",
    "\n",
    "# Training\n",
    "for e in range(train_epoch):\n",
    "    \n",
    "    model.train()\n",
    "    # keep track of the loss over an epoch\n",
    "    running_train_loss = 0\n",
    "    running_valid_loss = 0\n",
    "    running_train_correct = 0\n",
    "    running_val_correct = 0\n",
    "    y_train_true = []\n",
    "    y_train_pred = []\n",
    "    y_valid_true = []\n",
    "    y_valid_pred = []\n",
    "    batch = 0\n",
    "    for x_batch, y_batch in training_generator:\n",
    "        batch += 1\n",
    "        if torch.cuda.is_available():\n",
    "            x_batch, y_batch = x_batch.cuda(), y_batch.cuda() \n",
    "        \n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        y_pred = model(x_batch)  # for all tasks\n",
    "        \n",
    "        # Compute loss over all tasks\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        y_train_true_task = []\n",
    "        y_train_pred_task = []\n",
    "        for i in range(len(all_tasks)):\n",
    "            y_batch_task = y_batch[:,i]\n",
    "            y_pred_task  = y_pred[i][:,0] #check if predictions na\n",
    "            \n",
    "            # compute loss for labels that are not NA\n",
    "            indice_valid = y_batch_task >= 0\n",
    "            loss_task = criterion(y_pred_task[indice_valid], y_batch_task[indice_valid]) / N_train[i]\n",
    "            \n",
    "            loss += loss_task\n",
    "\n",
    "            pred_train = np.round(y_pred_task[indice_valid].detach().cpu().numpy())\n",
    "            target_train = y_batch_task[indice_valid].float()\n",
    "            y_train_true.extend(target_train.tolist()) \n",
    "            y_train_pred.extend(pred_train.reshape(-1).tolist())\n",
    "\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        writer.add_scalar(\"Accuracy/train\", loss, batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        # sum up the losses from each batch\n",
    "        running_train_loss += loss.item()\n",
    "        writer.add_scalar(\"Loss/train\", running_train_loss, e)\n",
    "        \n",
    "    else:\n",
    "        with torch.no_grad():    \n",
    "        ## evaluation part \n",
    "            model.eval()\n",
    "            for val_x_batch, val_y_batch in valid_generator:\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    val_x_batch, val_y_batch = val_x_batch.cuda(), val_y_batch.cuda() \n",
    "                \n",
    "                val_output = model(val_x_batch)\n",
    "\n",
    "                ## 2. loss calculation over all tasks \n",
    "                val_loss = 0\n",
    "                val_correct = 0\n",
    "                y_valid_true_task = []\n",
    "                y_valid_pred_task = []\n",
    "                for i in range(len(all_tasks)):\n",
    "                    val_y_batch_task = val_y_batch[:,i]\n",
    "                    val_output_task  = val_output[i][:,0]\n",
    "\n",
    "                    # compute loss for labels that are not NA\n",
    "                    indice_valid = val_y_batch_task >= 0\n",
    "                    val_loss_task = criterion(val_output_task[indice_valid], val_y_batch_task[indice_valid]) / N_valid[i]\n",
    "\n",
    "                    val_loss += val_loss_task\n",
    "                    \n",
    "                    pred_valid = np.round(val_output_task[indice_valid].detach().cpu().numpy())\n",
    "                    target_valid = val_y_batch_task[indice_valid].float()\n",
    "                    y_valid_true.extend(target_valid.tolist()) \n",
    "                    y_valid_pred.extend(pred_valid.reshape(-1).tolist())\n",
    "                \n",
    "\n",
    "                running_valid_loss+=val_loss.item()\n",
    "                writer.add_scalar(\"Loss/valid\", running_valid_loss, e)\n",
    "        \n",
    "        #epoch loss\n",
    "        train_epoch_loss=np.mean(running_train_loss)\n",
    "        val_epoch_loss=np.mean(running_valid_loss)  \n",
    "       \n",
    "        #epoch accuracy     \n",
    "        train_epoch_acc = accuracy_score(y_train_true,y_train_pred)\n",
    "        val_epoch_acc = accuracy_score(y_valid_true,y_valid_pred)\n",
    "        \n",
    "        #history\n",
    "        loss_history.append(train_epoch_loss)  \n",
    "        correct_history.append(train_epoch_acc)\n",
    "        val_loss_history.append(val_epoch_loss)  \n",
    "        val_correct_history.append(val_epoch_acc)  \n",
    "        \n",
    "        print(\"Epoch:\", e, \"Training Loss:\", train_epoch_loss, \"Valid Loss:\", val_epoch_loss)\n",
    "        print(\"Training Acc:\", train_epoch_acc, \"Valid Acc:\", val_epoch_acc)\n",
    "        \n",
    "        # create checkpoint variable and add important data\n",
    "        checkpoint = {\n",
    "            'epoch': e + 1,\n",
    "            'train_loss_min': train_epoch_loss,\n",
    "            'val_loss_min': val_epoch_loss, \n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }\n",
    "        \n",
    "        # save checkpoint\n",
    "        save_ckp(checkpoint, False, checkpoint_path, bestmodel_path)\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if train_epoch_loss <= train_loss_min:\n",
    "            print('Training loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(train_loss_min,train_epoch_loss))\n",
    "            # save checkpoint as best model\n",
    "            save_ckp(checkpoint, True, checkpoint_path, bestmodel_path)\n",
    "            train_loss_min = train_epoch_loss\n",
    "            \n",
    "        if train_epoch_loss >= val_epoch_loss:\n",
    "            print('Training loss greater than validation loss ({:.6f} --> {:.6f}).  Saving model ...'.format(train_epoch_loss,val_epoch_loss))\n",
    "            # save checkpoint as best model\n",
    "            save_ckp(checkpoint, True, checkpoint_path, bestmodel_byvalid_crossed)\n",
    "            train_loss_min = train_epoch_loss\n",
    "            \n",
    "        if val_epoch_loss <= val_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}). Saving model ...'.format(val_loss_min,val_epoch_loss))\n",
    "            # save checkpoint as best model\n",
    "            save_ckp(checkpoint, True, checkpoint_path, bestmodel_byvalid)\n",
    "            val_loss_min = val_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads model at lowest validation loss \n",
    "loaded_model, optimizer, start_epoch, train_loss_min = load_ckp(bestmodel_byvalid, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model = \", loaded_model)\n",
    "print(\"optimizer = \", optimizer)\n",
    "print(\"start_epoch = \", start_epoch)\n",
    "print(\"train_loss_min = \", train_loss_min)\n",
    "print(\"train_loss_min = {:.6f}\".format(train_loss_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print test loss\n",
    "for x_test_torch, y_test_torch in testing_generator:\n",
    "    y_test_pred = model.eval().to(device).cpu()(x_test_torch)\n",
    "    \n",
    "    # Compute loss over all tasks\n",
    "    loss = 0\n",
    "    for i in range(len(all_tasks)):\n",
    "        y_test_task = y_test_torch[:,i]\n",
    "        y_pred_task  = y_test_pred[i][:,0]\n",
    "\n",
    "        # compute loss for labels that are not NA\n",
    "        indice_valid = y_test_task >= 0\n",
    "        loss_task = criterion(y_pred_task[indice_valid], y_test_task[indice_valid]) / N_test[i]\n",
    "\n",
    "        loss += loss_task\n",
    "    \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "# Collects performance metrics for all tasks on test set in base model\n",
    "for i in range(len(all_tasks)):\n",
    "    \n",
    "    valid_datapoints = y_test[:,i] >= 0\n",
    "    y_test_task = y_test[valid_datapoints,i] \n",
    "    y_test_pred_task = y_test_pred[i].detach().numpy()[valid_datapoints,0]\n",
    "    \n",
    "    acc = accuracy_score(y_test_task, np.round(y_test_pred_task))\n",
    "    print('Accuracy for MTDNN on Morgan Fingerprint:', acc)\n",
    "    \n",
    "    bacc = sk.metrics.balanced_accuracy_score(y_test_task, np.round(y_test_pred_task))\n",
    "\n",
    "    f1 = f1_score(y_test_task, np.round(y_test_pred_task), pos_label=1)\n",
    "    print('F1 for MTDNN on Morgan Fingerprint:', f1)\n",
    "\n",
    "    cfm = sk.metrics.confusion_matrix(y_test_task, np.round(y_test_pred_task))\n",
    "    cfm = cfm / cfm.astype(np.float).sum(axis=1)\n",
    "\n",
    "    tn, fp, fn, tp = cfm.ravel()\n",
    "    pr = tp / (tp + fp)\n",
    "    rc = tp / (tp + fn)\n",
    "    print(' True Positive:', tp)\n",
    "    print(' True Negative:', tn)\n",
    "    print('False Positive:', fp)\n",
    "    print('False Negative:', fn)\n",
    "    \n",
    "    \n",
    "    auc = roc_auc_score(y_test_task, y_test_pred_task)\n",
    "    print('Test ROC AUC ({}):'.format(all_tasks[i]), auc)\n",
    "    \n",
    "    results[all_tasks[i]] = [auc, acc, bacc, tn, tp, pr, rc, f1]\n",
    "\n",
    "    fpr, tpr, threshold = sk.metrics.roc_curve(y_test_task, y_test_pred_task)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Task'.ljust(10), '\\t', '  AUC ', ' ACC ', ' BACC ', ' TN  ', ' TP  ', ' PR  ', ' RC  ', ' F1  ')\n",
    "for task, auc in results.items():\n",
    "    print(task.ljust(10), '\\t', np.round(auc,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### See Valid set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print test loss\n",
    "for x_valid_torch, y_valid_torch in valid_generator:\n",
    "    y_valid_pred = model.eval().to(device).cpu()(x_valid_torch)\n",
    "    \n",
    "    # Compute loss over all tasks\n",
    "    loss = 0\n",
    "    for i in range(len(all_tasks)):\n",
    "        y_test_task = y_valid_torch[:,i]\n",
    "        y_pred_task  = y_valid_pred[i][:,0]\n",
    "\n",
    "        # compute loss for labels that are not NA\n",
    "        indice_valid = y_test_task >= 0\n",
    "        loss_task = criterion(y_pred_task[indice_valid], y_test_task[indice_valid]) / N_valid[i]\n",
    "\n",
    "        loss += loss_task\n",
    "    \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_valid = {}\n",
    "# Collects performance metrics for all tasks on valid set in base model\n",
    "for i in range(len(all_tasks)):\n",
    "    \n",
    "    valid_datapoints = y_valid[:,i] >= 0\n",
    "    y_valid_task = y_valid[valid_datapoints,i] \n",
    "    y_valid_pred_task = y_valid_pred[i].detach().numpy()[valid_datapoints,0]\n",
    "    \n",
    "    \n",
    "    acc = accuracy_score(y_valid_task, np.round(y_valid_pred_task))\n",
    "    print('Accuracy for deepnn on Morgan Fingerprint:', acc)\n",
    "    \n",
    "    bacc = sk.metrics.balanced_accuracy_score(y_valid_task, np.round(y_valid_pred_task))\n",
    "\n",
    "    f1 = f1_score(y_valid_task, np.round(y_valid_pred_task), pos_label=1)\n",
    "    print('F1 for deepnn on Morgan Fingerprint:', f1)\n",
    "\n",
    "    cfm = sk.metrics.confusion_matrix(y_valid_task, np.round(y_valid_pred_task))\n",
    "    cfm = cfm / cfm.astype(np.float).sum(axis=1)\n",
    "\n",
    "    print('Confusion Matrix for deepnn on Morgan Fingerprint:\\n', cfm)\n",
    "\n",
    "    tn, fp, fn, tp = cfm.ravel()\n",
    "    pr = tp / (tp + fp)\n",
    "    rc = tp / (tp + fn)\n",
    "    print(' True Positive:', tp)\n",
    "    print(' True Negative:', tn)\n",
    "    print('False Positive:', fp)\n",
    "    print('False Negative:', fn)\n",
    "    \n",
    "    \n",
    "    auc = roc_auc_score(y_valid_task, y_valid_pred_task)\n",
    "    print('Test ROC AUC ({}):'.format(all_tasks[i]), auc)\n",
    "    \n",
    "    results_valid[all_tasks[i]] = [auc, acc, bacc, tn, tp, pr, rc, f1]\n",
    "\n",
    "    fpr, tpr, threshold = sk.metrics.roc_curve(y_valid_task, y_valid_pred_task)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Task'.ljust(35), '\\t', '  AUC ', ' ACC ', ' BACC ', ' TN  ', ' TP  ', ' PR  ', ' RC  ', ' F1  ')\n",
    "for task, auc in results_valid.items():\n",
    "    print(task.ljust(35), '\\t', np.round(auc,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_modelpath = # define pathway for base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(base_modelpath):\n",
    "    os.makedirs(base_modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow saved model\n",
    "torch.save(model.state_dict(), base_modelpath+f'base_mtdnn_rtecs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = base_modelpath+f'base_mtdnn_rtecs.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = \"blue\"> Transfer Learning </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load ClinTox Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tasks = ['CT_TOX']\n",
    "task = all_tasks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ct = [clintox_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load ClinTox split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved clintox train/test/valid data\n",
    "clintox_data_path = f\"../../data/datasets/clintox/split_data/seed_{seed_value}/\" \n",
    "train_data_ct=torch.load(clintox_data_path + 'train_data_clintox.pth')\n",
    "test_data_ct=torch.load(clintox_data_path + 'test_data_clintox.pth')\n",
    "valid_data_ct=torch.load(clintox_data_path + 'valid_data_clintox.pth')\n",
    "\n",
    "data_ct = [train_data_ct, test_data_ct, valid_data_ct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of examples, train: \" + str(data_ct[0].shape[0]))\n",
    "print(\"Total number of examples, test: \" + str(data_ct[1].shape[0]))\n",
    "print(\"Total number of examples, valid: \" + str(data_ct[2].shape[0]))\n",
    "print(\"Total number of examples, train+test+valid: \" + str(data_ct[0].shape[0] + data_ct[1].shape[0] + data_ct[2].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct FP for ClinTox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(len(data_ct)):\n",
    "    data_ct[i]['mol'] = [rd.Chem.MolFromSmiles(x) for x in data_ct[i]['smiles']]\n",
    "\n",
    "    bi = [{} for _ in range(len(data_ct[i]))]\n",
    "    data_ct[i]['morgan'] = [AllChem.GetMorganFingerprintAsBitVect(data_ct[i].iloc[j]['mol'], morgan_radius, nBits = morgan_bits, bitInfo=bi[j]) \n",
    "                         for j in range(len(data_ct[i]))]\n",
    "    data_ct[i]['bitInfo'] = bi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create train, test, valid sets for ClinTox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ct = [train_data_ct, test_data_ct, valid_data_ct]\n",
    "\n",
    "# replace NA with -1 -- used to deal with missing labels, \n",
    "#                       along with Binary Cross-Entropy loss\n",
    "data_ct[0] = data_ct[0].fillna(-1)\n",
    "data_ct[1] = data_ct[1].fillna(-1)\n",
    "data_ct[2] = data_ct[2].fillna(-1)\n",
    "\n",
    "train_data_ct = data_ct[0]\n",
    "test_data_ct  = data_ct[1]\n",
    "valid_data_ct = data_ct[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the RDKit explicit vectors into numpy arrays\n",
    "x_train_ct = []\n",
    "for fp in train_data_ct['morgan']:\n",
    "    arr = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    x_train_ct.append(arr)\n",
    "x_train_ct = np.array(x_train_ct)\n",
    "x_train_ct = x_train_ct - 0.5\n",
    "\n",
    "y_train_ct = train_data_ct[all_tasks].values\n",
    "\n",
    "# convert the RDKit explicit vectors into numpy arrays\n",
    "x_test_ct = []\n",
    "for fp in test_data_ct['morgan']:\n",
    "    arr = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    x_test_ct.append(arr)\n",
    "x_test_ct = np.array(x_test_ct)\n",
    "x_test_ct = x_test_ct - 0.5\n",
    "\n",
    "y_test_ct = test_data_ct[all_tasks].values\n",
    "\n",
    "# convert the RDKit explicit vectors into numpy arrays\n",
    "x_valid_ct = []\n",
    "for fp in valid_data_ct['morgan']:\n",
    "    arr = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    x_valid_ct.append(arr)\n",
    "x_valid_ct = np.array(x_valid_ct)\n",
    "x_valid_ct = x_valid_ct - 0.5\n",
    "\n",
    "y_valid_ct = valid_data_ct[all_tasks].values\n",
    "\n",
    "# count the number of data points per class\n",
    "N_train_ct = np.sum(y_train_ct >= 0, 0)\n",
    "N_test_ct  = np.sum(y_test_ct >= 0, 0)\n",
    "N_valid_ct  = np.sum(y_valid_ct >= 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data for pytorch\n",
    "x_train_torch_ct = x_train_ct.astype(np.float32)\n",
    "y_train_torch_ct = y_train_ct.astype(np.float32)\n",
    "\n",
    "x_test_torch_ct = x_test_ct.astype(np.float32)\n",
    "y_test_torch_ct = y_test_ct.astype(np.float32)\n",
    "\n",
    "x_valid_torch_ct = x_valid_ct.astype(np.float32)\n",
    "y_valid_torch_ct = y_valid_ct.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train_torch_ct.shape[1]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_ct = MTDNNData(x_train_torch_ct, y_train_torch_ct)\n",
    "training_generator_ct = DataLoader(training_set_ct, batch_size=batch, shuffle=True)\n",
    "\n",
    "testing_set_ct = MTDNNData(x_test_torch_ct, y_test_torch_ct)\n",
    "testing_generator_ct = DataLoader(testing_set_ct, batch_size=len(testing_set_ct), shuffle=False)\n",
    "\n",
    "valid_set_ct = MTDNNData(x_valid_torch_ct, y_valid_torch_ct)\n",
    "valid_generator_ct = DataLoader(valid_set_ct, batch_size=len(valid_set_ct), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define base model, containing only the two shared layers of the MTDNN and its trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MTDNN base model - contains only the first two shared layers of the base model \n",
    "\n",
    "class MTDNN_base(torch.nn.Module):\n",
    "    def __init__(self, input_shape, all_tasks):\n",
    "        super(MTDNN_base, self).__init__()\n",
    "\n",
    "        # neural network layers\n",
    "        self.shared_1 = torch.nn.Linear(input_shape, 2048)\n",
    "        self.batchnorm_1 = torch.nn.BatchNorm1d(2048)\n",
    "        \n",
    "        self.shared_2 = torch.nn.Linear(2048, 1024)\n",
    "        self.batchnorm_2 = torch.nn.BatchNorm1d(1024)\n",
    "        \n",
    "        # function for leaky ReLU\n",
    "        self.leakyReLU = torch.nn.LeakyReLU(0.05)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # shared layers\n",
    "        x = self.shared_1(x)\n",
    "        x = self.batchnorm_1(x)\n",
    "        x = self.leakyReLU(x)\n",
    "        \n",
    "        x = self.shared_2(x)\n",
    "        x = self.batchnorm_2(x)\n",
    "        x = self.leakyReLU(x)\n",
    " \n",
    "        return x\n",
    "    \n",
    "base_model_rtecs = MTDNN_base(input_shape, all_tasks).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained parameters of base model\n",
    "\n",
    "pretrained_dict = torch.load(base, map_location=device)\n",
    "base_model_rtecs_dict = base_model_rtecs.state_dict()\n",
    "# remove the keys corresponing to the linear layer in the pretrained base dict\n",
    "import itertools  \n",
    "from collections import OrderedDict\n",
    "N = 14\n",
    "loaded_dict = OrderedDict(itertools.islice(pretrained_dict.items(), N))  \n",
    "\n",
    "# now update the model dict with pretrained dict\n",
    "base_model_rtecs_dict.update(loaded_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make sure we only have the first two layers of the MTDNN base_model_rtecs = torch.nn.Sequential(*(list(base_model_rtecs.children())[0:5]))\n",
    "for param in base_model_rtecs.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_rtecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add two layers to base model to train on ClinTox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_rtecs.hidden_ct_1 = torch.nn.Linear(1024, 512)\n",
    "base_model_rtecs.batchnorm_1 = torch.nn.BatchNorm1d(512)\n",
    "\n",
    "base_model_rtecs.hidden_ct_2 = torch.nn.Linear(512, 256)\n",
    "base_model_rtecs.batchnorm_2 = torch.nn.BatchNorm1d(256)\n",
    "base_model_rtecs.output = torch.nn.Linear(256, 1)\n",
    "base_model_rtecs.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "\n",
    "base_model_rtecs = base_model_rtecs.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_rtecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = # define path to save TL model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Pathways to save models \n",
    "checkpoint_path = path + '/current_checkpoint.pt'\n",
    "\n",
    "#Path to saved model when train_epoch_loss <= train_loss_min\n",
    "bestmodel_path = path + '/best_model.pt'  \n",
    "\n",
    "#Path to saved model at minimum valid loss\n",
    "bestmodel_byvalid = path + '/best_model_by_valid.pt' \n",
    "\n",
    "#Path to saved  when train_epoch_loss >= val_epoch_loss\n",
    "bestmodel_byvalid_crossed = path + '/best_model_by_valid-crossed.pt'   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train TL model with ClinTox - 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Freeze the layers of the base model \n",
    "count = 0\n",
    "for param in base_model_rtecs.parameters():\n",
    "    count +=1\n",
    "    if count < 6: #freezing first 5 layers\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# Optimizers require the parameters to optimize and a learning rate, providing the parameters of the base model too\n",
    "optimizer_ct = torch.optim.Adam(filter(lambda p: p.requires_grad, base_model_rtecs.parameters()), lr = 0.001)\n",
    "for state in optimizer_ct.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only one epoch training with added ClinTox layers - to ensure not heavily trained on ClinTox\n",
    "train_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "##################### With Tensorboard ######################\n",
    "loss_history=[]  \n",
    "correct_history=[]  \n",
    "val_loss_history=[]  \n",
    "val_correct_history=[] \n",
    "train_loss_min = np.Inf\n",
    "val_loss_min = np.Inf\n",
    "\n",
    "# Training\n",
    "for e in range(train_epoch):\n",
    "    \n",
    "    base_model_rtecs.train()\n",
    "    # keep track of the loss over an epoch\n",
    "    running_train_loss = 0\n",
    "    running_valid_loss = 0\n",
    "    running_train_correct = 0\n",
    "    running_val_correct = 0\n",
    "    y_train_true = []\n",
    "    y_train_pred = []\n",
    "    y_valid_true = []\n",
    "    y_valid_pred = []\n",
    "    batch_num = 0\n",
    "    for x_batch, y_batch in training_generator_ct:\n",
    "        batch_num += 1\n",
    "        if torch.cuda.is_available():\n",
    "            x_batch, y_batch = x_batch.cuda(), y_batch.cuda() \n",
    "        \n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        y_pred = base_model_rtecs(x_batch)  # for all tasks\n",
    "        \n",
    "        # Compute loss over all tasks\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        y_train_true_task = []\n",
    "        y_train_pred_task = []\n",
    "        for i in range(len(all_tasks)):\n",
    "            y_batch_task = y_batch[:,i]\n",
    "            y_pred_task  = y_pred[:,0] #check if predictions na\n",
    "            \n",
    "            # compute loss for labels that are not NA\n",
    "            indice_valid = y_batch_task >= 0\n",
    "            loss_task = criterion(y_pred_task[indice_valid], y_batch_task[indice_valid]) / N_train_ct[i]\n",
    "            \n",
    "            loss += loss_task\n",
    "\n",
    "            pred_train = np.round(y_pred_task[indice_valid].detach().cpu().numpy())\n",
    "            target_train = y_batch_task[indice_valid].float()\n",
    "            y_train_true.extend(target_train.tolist()) \n",
    "            y_train_pred.extend(pred_train.reshape(-1).tolist())\n",
    "\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer_ct.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_ct.step()\n",
    "    \n",
    "        # sum up the losses from each batch\n",
    "        running_train_loss += loss.item()\n",
    "        writer.add_scalar(\"Loss/train\", running_train_loss, e)\n",
    "        \n",
    "    else:\n",
    "        with torch.no_grad():    \n",
    "        ## evaluation part \n",
    "            base_model_rtecs.eval()\n",
    "            for val_x_batch, val_y_batch in valid_generator_ct:\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    val_x_batch, val_y_batch = val_x_batch.cuda(), val_y_batch.cuda() \n",
    "                \n",
    "                val_output = base_model_rtecs(val_x_batch)\n",
    "\n",
    "                ## 2. loss calculation over all tasks \n",
    "                val_loss = 0\n",
    "                val_correct = 0\n",
    "                y_valid_true_task = []\n",
    "                y_valid_pred_task = []\n",
    "                for i in range(len(all_tasks)):\n",
    "                    val_y_batch_task = val_y_batch[:,i]\n",
    "                    val_output_task  = val_output[:,0]\n",
    "\n",
    "                    # compute loss for labels that are not NA\n",
    "                    indice_valid = val_y_batch_task >= 0\n",
    "                    val_loss_task = criterion(val_output_task[indice_valid], val_y_batch_task[indice_valid]) / N_valid_ct[i]\n",
    "\n",
    "                    val_loss += val_loss_task\n",
    "                    \n",
    "                    pred_valid = np.round(val_output_task[indice_valid].detach().cpu().numpy())\n",
    "                    target_valid = val_y_batch_task[indice_valid].float()\n",
    "                    y_valid_true.extend(target_valid.tolist()) \n",
    "                    y_valid_pred.extend(pred_valid.reshape(-1).tolist())\n",
    "\n",
    "                running_valid_loss+=val_loss.item()\n",
    "                writer.add_scalar(\"Loss/valid\", running_valid_loss, e)\n",
    "        \n",
    "        #epoch loss\n",
    "        train_epoch_loss=np.mean(running_train_loss)\n",
    "        val_epoch_loss=np.mean(running_valid_loss)  \n",
    "       \n",
    "        #epoch accuracy     \n",
    "        train_epoch_acc = accuracy_score(y_train_true,y_train_pred)\n",
    "        val_epoch_acc = accuracy_score(y_valid_true,y_valid_pred)\n",
    "        \n",
    "        #history\n",
    "        loss_history.append(train_epoch_loss)  \n",
    "        correct_history.append(train_epoch_acc)\n",
    "        val_loss_history.append(val_epoch_loss)  \n",
    "        val_correct_history.append(val_epoch_acc)  \n",
    "        \n",
    "        print(\"Epoch:\", e, \"Training Loss:\", train_epoch_loss, \"Valid Loss:\", val_epoch_loss)\n",
    "        print(\"Training Acc:\", train_epoch_acc, \"Valid Acc:\", val_epoch_acc)\n",
    "        \n",
    "        # create checkpoint variable and add important data\n",
    "        checkpoint = {\n",
    "            'epoch': e + 1,\n",
    "            'train_loss_min': train_epoch_loss,\n",
    "            'val_loss_min': val_epoch_loss, \n",
    "            'state_dict': base_model_rtecs.state_dict(),\n",
    "            'optimizer': optimizer_ct.state_dict(),\n",
    "        }\n",
    "        \n",
    "        # save checkpoint\n",
    "        save_ckp(checkpoint, False, checkpoint_path_ct, bestmodel_path_ct)\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if train_epoch_loss <= train_loss_min:\n",
    "            print('Training loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(train_loss_min,train_epoch_loss))\n",
    "            # save checkpoint as best model\n",
    "            save_ckp(checkpoint, True, checkpoint_path_ct, bestmodel_path_ct)\n",
    "            train_loss_min = train_epoch_loss\n",
    "            \n",
    "        if train_epoch_loss >= val_epoch_loss:\n",
    "            print('Training loss greater than validation loss ({:.6f} --> {:.6f}).  Saving model ...'.format(train_epoch_loss,val_epoch_loss))\n",
    "            # save checkpoint as best model\n",
    "            save_ckp(checkpoint, True, checkpoint_path_ct, bestmodel_byvalid_crossed_ct)\n",
    "            train_loss_min = train_epoch_loss\n",
    "            \n",
    "        if val_epoch_loss <= val_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}). Saving model ...'.format(val_loss_min,val_epoch_loss))\n",
    "            # save checkpoint as best model\n",
    "            save_ckp(checkpoint, True, checkpoint_path_ct, bestmodel_byvalid_ct)\n",
    "            val_loss_min = val_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TL model with lowest valid loss \n",
    "loaded_model_ct, optimizer_ct, start_epoch, valid_loss_min, train_loss_min = load_ckp(bestmodel_byvalid_ct, base_model_rtecs, optimizer_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model = \", loaded_model_ct)\n",
    "print(\"optimizer = \", optimizer_ct)\n",
    "print(\"start_epoch = \", start_epoch)\n",
    "print(\"val_loss_min = {:.6f}\".format(val_loss_min))\n",
    "print(\"train_loss_min = {:.6f}\".format(train_loss_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate test performance of TL model on ClinTox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print test loss\n",
    "for x_test_torch, y_test_torch in testing_generator_ct:\n",
    "    y_test_pred = loaded_model_ct.eval().to(device).cpu()(x_test_torch)\n",
    "    \n",
    "    # Compute loss over all tasks\n",
    "    loss = 0\n",
    "    for i in range(len(all_tasks)):\n",
    "        y_test_task = y_test_torch[:,i]\n",
    "        y_pred_task  = y_test_pred[:,0]\n",
    "\n",
    "        # compute loss for labels that are not NA\n",
    "        indice_valid = y_test_task >= 0\n",
    "        loss_task = criterion(y_pred_task[indice_valid], y_test_task[indice_valid]) / N_test_ct[i]\n",
    "\n",
    "        loss += loss_task\n",
    "    \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ct = {}\n",
    "# Collects performance metrics on ClinTox for test set\n",
    "# Note ClinTox is very skewed, for this test set there were no \"toxic\" samples. \n",
    "for i in range(len(all_tasks)):\n",
    "    \n",
    "    valid_datapoints = y_test_ct[:,i] >= 0\n",
    "    y_test_task = y_test_ct[valid_datapoints,i] \n",
    "    y_test_pred_task = y_test_pred.detach().numpy()[valid_datapoints,0]\n",
    "    \n",
    "    acc = accuracy_score(y_test_task, np.round(y_test_pred_task))\n",
    "    print('Accuracy for MTDNN on Morgan Fingerprint:', acc)\n",
    "    \n",
    "    bacc = sk.metrics.balanced_accuracy_score(y_test_task, np.round(y_test_pred_task))\n",
    "\n",
    "    f1 = f1_score(y_test_task, np.round(y_test_pred_task), pos_label=1)\n",
    "    print('F1 for MTDNN on Morgan Fingerprint:', f1)\n",
    "\n",
    "    cfm = sk.metrics.confusion_matrix(y_test_task, np.round(y_test_pred_task))\n",
    "    cfm = cfm / cfm.astype(np.float).sum(axis=1)\n",
    "\n",
    "    tn, fp, fn, tp = cfm.ravel()\n",
    "    pr = tp / (tp + fp)\n",
    "    rc = tp / (tp + fn)\n",
    "    print(' True Positive:', tp)\n",
    "    print(' True Negative:', tn)\n",
    "    print('False Positive:', fp)\n",
    "    print('False Negative:', fn)\n",
    "    \n",
    "    \n",
    "    auc = roc_auc_score(y_test_task, y_test_pred_task)\n",
    "    print('Test ROC AUC ({}):'.format(all_tasks[i]), auc)\n",
    "    \n",
    "    results_ct[all_tasks[i]] = [auc, acc, bacc, tn, tp, pr, rc, f1]\n",
    "\n",
    "    fpr, tpr, threshold = sk.metrics.roc_curve(y_test_task, y_test_pred_task)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Task'.ljust(10), '\\t', '  AUC ', ' ACC ', ' BACC ', ' TN  ', ' TP  ', ' PR  ', ' RC  ', ' F1  ')\n",
    "for task, auc in results_ct.items():\n",
    "    print(task.ljust(10), '\\t', np.round(auc,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate valid performance of TL model on ClinTox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print test loss\n",
    "for x_valid_torch, y_valid_torch in valid_generator_ct:\n",
    "    y_valid_pred = base_model_rtecs.eval().to(device).cpu()(x_valid_torch)\n",
    "    \n",
    "    # Compute loss over all tasks\n",
    "    loss = 0\n",
    "    for i in range(len(all_tasks)):\n",
    "        y_test_task = y_valid_torch[:,i]\n",
    "        y_pred_task  = y_valid_pred[:,0]\n",
    "\n",
    "        # compute loss for labels that are not NA\n",
    "        indice_valid = y_test_task >= 0\n",
    "        loss_task = criterion(y_pred_task[indice_valid], y_test_task[indice_valid]) / N_valid_ct[i]\n",
    "\n",
    "        loss += loss_task\n",
    "    \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_valid_ct = {}\n",
    "# Collects performance metrics on ClinTox for valid set\n",
    "for i in range(len(all_tasks)):\n",
    "    \n",
    "    valid_datapoints = y_valid_ct[:,i] >= 0\n",
    "    y_valid_task = y_valid_ct[valid_datapoints,i] \n",
    "    y_valid_pred_task = y_valid_pred.detach().numpy()[valid_datapoints,0]\n",
    "    \n",
    "    \n",
    "    acc = accuracy_score(y_valid_task, np.round(y_valid_pred_task))\n",
    "    print('Accuracy for deepnn on Morgan Fingerprint:', acc)\n",
    "    \n",
    "    bacc = sk.metrics.balanced_accuracy_score(y_valid_task, np.round(y_valid_pred_task))\n",
    "\n",
    "    f1 = f1_score(y_valid_task, np.round(y_valid_pred_task), pos_label=1)\n",
    "    print('F1 for deepnn on Morgan Fingerprint:', f1)\n",
    "\n",
    "    cfm = sk.metrics.confusion_matrix(y_valid_task, np.round(y_valid_pred_task))#normalize='true'\n",
    "    cfm = cfm / cfm.astype(np.float).sum(axis=1)\n",
    "\n",
    "    print('Confusion Matrix for deepnn on Morgan Fingerprint:\\n', cfm)\n",
    "\n",
    "    tn, fp, fn, tp = cfm.ravel()\n",
    "    pr = tp / (tp + fp)\n",
    "    rc = tp / (tp + fn)\n",
    "    print(' True Positive:', tp)\n",
    "    print(' True Negative:', tn)\n",
    "    print('False Positive:', fp)\n",
    "    print('False Negative:', fn)\n",
    "    \n",
    "    \n",
    "    auc = roc_auc_score(y_valid_task, y_valid_pred_task)\n",
    "    print('Test ROC AUC ({}):'.format(all_tasks[i]), auc)\n",
    "    \n",
    "    results_valid_ct[all_tasks[i]] = [auc, acc, bacc, tn, tp, pr, rc, f1]\n",
    "\n",
    "    fpr, tpr, threshold = sk.metrics.roc_curve(y_valid_task, y_valid_pred_task)\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Task'.ljust(35), '\\t', '  AUC ', ' ACC ', ' BACC ', ' TN  ', ' TP  ', ' PR  ', ' RC  ', ' F1  ')\n",
    "for task, auc in results_valid_ct.items():\n",
    "    print(task.ljust(35), '\\t', np.round(auc,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
