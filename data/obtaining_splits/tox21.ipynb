{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This notebook generates train / valid / test (0.8 / 0.1 / 0.1) splits for Tox21, based on the random splitting method in MoleculeNet\n",
    "\n",
    "Splits were created for seeds of 122, 123, 124 (same seeds as MoleculeNet). \n",
    "\n",
    "All splits are saved in data/tox21/split_data folder \n",
    "\n",
    "Raw Tox21 data was obtained from MoleculeNet.\n",
    "- MoleculeNet Data: https://github.com/deepchem/deepchem/blob/7463d93d0f85a3ba58cd155209540d8e649d875e/deepchem/molnet/load_function/tox21_datasets.py specifies this location - \"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/tox21.csv.gz\"\n",
    "- MoleculeNet Splitting method: https://github.com/deepchem/deepchem/blob/master/deepchem/splits/splitters.py\n",
    "\n",
    "Tasks (endpoints) defined in the Tox21 are: \n",
    "- 'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD','NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general and data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "import time\n",
    "import random\n",
    "import joblib\n",
    "\n",
    "# Required RDKit modules\n",
    "import rdkit as rd\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "# modeling\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed value\n",
    "seed_value = 124 #122 123 124, as used in MoleculeNet\n",
    "torch.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "torch.backends.cudnn.enabled=False\n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of bits for morgan fingerprints\n",
    "morgan_bits = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of radius for morgan fingerprints\n",
    "morgan_radius = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tox21_file  = '../../data/datasets/tox21/raw_data/tox21.csv'\n",
    "tox21_tasks = ['NR-AR', 'NR-Aromatase', 'NR-PPAR-gamma', 'SR-HSE', \n",
    "               'NR-AR-LBD', 'NR-ER', 'SR-ARE', 'SR-MMP',\n",
    "               'NR-AhR', 'NR-ER-LBD', 'SR-ATAD5', 'SR-p53']\n",
    "\n",
    "tox21_data = pd.read_csv(tox21_file)\n",
    "print('Reading {}... {} data loaded.'.format(tox21_file, len(tox21_data)))\n",
    "tox21_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [tox21_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tasks = tox21_tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert SMILES to CANONICAL SMILES\n",
    "# In the process of canonicalizing SMILES, any bad SMILES definition \n",
    "#     is caught and removed from the dataset\n",
    "\n",
    "for i in range(len(data)):\n",
    "    smis = list(data[i].smiles)\n",
    "\n",
    "    cans = []\n",
    "    for smi in smis:\n",
    "        mol = rd.Chem.MolFromSmiles(smi)\n",
    "        # see whether can be parsed to mol\n",
    "        if mol:\n",
    "            can = rd.Chem.MolToSmiles(mol, True)\n",
    "            cans.append(can)\n",
    "        else:\n",
    "            cans.append(np.nan)\n",
    "\n",
    "    data[i]['SMILES'] = cans\n",
    "    \n",
    "    # drop data point that has invalid molecule\n",
    "    data[i] = data[i][data[i]['SMILES'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color = 'blue'> MoleculeNet Split </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Method borrowed from MoleculeNet for random splits of 0.8 / 0.1 / 0.1, train / test / valid \n",
    "# Returns index of random train, test, valid datasets in array of [train,test,valid]\n",
    "\n",
    "def split(dataset,\n",
    "            seed=None,\n",
    "            frac_train=.8,\n",
    "            frac_valid=.1,\n",
    "            frac_test=.1,\n",
    "            log_every_n=None):\n",
    "    \"\"\"\n",
    "        Splits internal compounds randomly into train/validation/test.\n",
    "        \"\"\"\n",
    "    np.testing.assert_almost_equal(frac_train + frac_valid + frac_test, 1.)\n",
    "    if not seed is None:\n",
    "        np.random.seed(seed)\n",
    "    num_datapoints = len(dataset)\n",
    "    train_cutoff = int(frac_train * num_datapoints)\n",
    "    valid_cutoff = int((frac_train + frac_valid) * num_datapoints)\n",
    "    shuffled = np.random.permutation(range(num_datapoints))\n",
    "    return (shuffled[:train_cutoff], shuffled[train_cutoff:valid_cutoff],\n",
    "            shuffled[valid_cutoff:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train_data = []\n",
    "temp_test_data = []\n",
    "temp_valid_data = []\n",
    "for i in range(len(data)):\n",
    "    splitter_i = split(data[i])\n",
    "    for j in range(len(splitter_i)):\n",
    "            if j==0: \n",
    "                temp_train_data.append(data[i].iloc[splitter_i[j]])\n",
    "            if j==1: \n",
    "                temp_test_data.append(data[i].iloc[splitter_i[j]])\n",
    "            if j==2: \n",
    "                temp_valid_data.append(data[i].iloc[splitter_i[j]])\n",
    "                \n",
    "train_data = temp_train_data[0]\n",
    "test_data  = temp_test_data[0]\n",
    "valid_data  = temp_valid_data[0]\n",
    "\n",
    "\n",
    "for i in range(1, len(data)):\n",
    "    train_data = train_data.merge(temp_train_data[i], how='outer', on='smiles')\n",
    "    test_data  = test_data.merge(temp_test_data[i], how='outer', on='smiles')\n",
    "    valid_data  = valid_data.merge(temp_valid_data[i], how='outer', on='smiles')\n",
    "\n",
    "\n",
    "data = [train_data, test_data, valid_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save data uncomment the path to dataset\n",
    "data_path = #f\"../../data/datasets/tox21/split_data/seed_{seed_value}/\"\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(data[0], data_path+\"train_data_tox21.pth\")\n",
    "torch.save(data[1], data_path+\"test_data_tox21.pth\")\n",
    "torch.save(data[2], data_path+\"valid_data_tox21.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check: load saved clintox train/test/valid data\n",
    "train_data=torch.load(data_path + 'train_data_tox21.pth')\n",
    "test_data=torch.load(data_path + 'test_data_tox21.pth')\n",
    "valid_data=torch.load(data_path + 'valid_data_tox21.pth')\n",
    "\n",
    "data = [train_data, test_data, valid_data]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
